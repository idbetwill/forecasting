# Documentaci√≥n T√©cnica: Forecasting Recursivo Multi-Step para Demanda Energ√©tica

## Tabla de Contenidos

1. [Introducci√≥n](#introducci√≥n)
2. [Arquitectura del Sistema](#arquitectura-del-sistema)
3. [An√°lisis Detallado del C√≥digo](#an√°lisis-detallado-del-c√≥digo)
4. [Funciones Principales](#funciones-principales)
5. [Flujo de Datos](#flujo-de-datos)
6. [Modelo de Machine Learning](#modelo-de-machine-learning)
7. [Visualizaciones](#visualizaciones)
8. [M√©tricas de Evaluaci√≥n](#m√©tricas-de-evaluaci√≥n)
9. [Casos de Uso](#casos-de-uso)
10. [Troubleshooting](#troubleshooting)

---

## Introducci√≥n

Este documento proporciona una explicaci√≥n t√©cnica detallada del notebook `forecasting_demanda_energia.ipynb`, que implementa un sistema de forecasting recursivo multi-step para la predicci√≥n de demanda energ√©tica utilizando la clase `ForecasterRecursive` de la librer√≠a skforecast.

### Objetivo Principal
Predecir la demanda energ√©tica del d√≠a siguiente (24 horas) utilizando un modelo de machine learning que aprende patrones temporales complejos de los datos hist√≥ricos.

### Metodolog√≠a
El forecasting recursivo multi-step utiliza las propias predicciones del modelo como entrada para predecir valores futuros, creando un proceso iterativo que captura dependencias temporales de largo plazo.

---

## Arquitectura del Sistema

```mermaid
graph TD
    A[Datos Excel 2000-2025] --> B[Carga y Procesamiento]
    B --> C[An√°lisis Exploratorio]
    C --> D[Partici√≥n Train/Val/Test]
    D --> E[Modelo Recursivo]
    E --> F[Evaluaci√≥n]
    F --> G[Predicci√≥n D√≠a Siguiente]
    G --> H[Visualizaciones]
    H --> I[Exportaci√≥n CSV]
```

### Componentes Principales

1. **Capa de Datos**: Carga y procesamiento de archivos Excel
2. **Capa de An√°lisis**: Exploraci√≥n y visualizaci√≥n de datos
3. **Capa de Modelado**: Implementaci√≥n del modelo recursivo
4. **Capa de Evaluaci√≥n**: M√©tricas y validaci√≥n
5. **Capa de Predicci√≥n**: Generaci√≥n de pron√≥sticos
6. **Capa de Visualizaci√≥n**: Gr√°ficos interactivos y est√°ticos

---

## An√°lisis Detallado del C√≥digo

### 1. Importaci√≥n de Librer√≠as

```python
# Tratamiento de datos
import numpy as np
import pandas as pd

# Visualizaci√≥n
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots

# Forecasting y ML
from skforecast.recursive import ForecasterRecursive
from skforecast.model_selection import TimeSeriesFold, backtesting_forecaster
from skforecast.preprocessing import RollingFeatures
from lightgbm import LGBMRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
```

**Prop√≥sito**: Importar todas las dependencias necesarias para el procesamiento de datos, modelado y visualizaci√≥n.

**Librer√≠as Clave**:
- `skforecast`: Framework especializado en forecasting de series temporales
- `lightgbm`: Algoritmo de gradient boosting para el modelo base
- `plotly`: Visualizaciones interactivas
- `matplotlib/seaborn`: Visualizaciones est√°ticas

### 2. Carga y Procesamiento de Datos

#### Funci√≥n `load_energy_data()`

```python
def load_energy_data():
    """
    Carga y procesa los datos de demanda energ√©tica desde m√∫ltiples archivos Excel
    """
    import os
    import glob
    
    # Buscar archivos Excel en la carpeta demanda-energia-sin/
    data_folder = 'demanda-energia-sin'
    excel_files = glob.glob(os.path.join(data_folder, '*.xlsx'))
    excel_files.sort()
    
    # Cargar y combinar todos los archivos
    all_data = []
    for file_path in excel_files:
        df = pd.read_excel(file_path, header=3)
        year = os.path.basename(file_path).split('_')[-1].replace('.xlsx', '')
        df['year'] = int(year)
        all_data.append(df)
    
    datos = pd.concat(all_data, ignore_index=True)
    return datos
```

**Funcionalidad**:
- **Detecci√≥n autom√°tica**: Busca todos los archivos `.xlsx` en la carpeta
- **Carga secuencial**: Lee cada archivo con header en fila 3
- **Extracci√≥n de metadatos**: Obtiene el a√±o del nombre del archivo
- **Concatenaci√≥n**: Combina todos los datos en un DataFrame √∫nico

**Par√°metros**:
- `header=3`: Los datos comienzan en la fila 4 (0-indexed)
- `ignore_index=True`: Reinicia el √≠ndice al concatenar

#### Funci√≥n `preprocess_data()`

```python
def preprocess_data(datos_raw):
    """
    Procesa los datos para crear una serie temporal de demanda energ√©tica
    """
    # Detectar columnas autom√°ticamente
    date_columns = []
    demand_columns = []
    
    for col in datos_raw.columns:
        col_lower = col.lower()
        if any(keyword in col_lower for keyword in ['fecha', 'date', 'time', 'tiempo']):
            date_columns.append(col)
        if any(keyword in col_lower for keyword in ['demanda', 'demand', 'consumo', 'consumption', 'energia', 'energy']):
            demand_columns.append(col)
    
    # Preparar datos
    datos = datos_raw[[date_col, demand_col]].copy()
    datos.columns = ['Time', 'Demand']
    
    # Convertir fecha y limpiar
    datos['Time'] = pd.to_datetime(datos['Time'], errors='coerce')
    datos = datos.dropna()
    datos = datos.set_index('Time')
    datos = datos.sort_index()
```

**Funcionalidad**:
- **Detecci√≥n inteligente**: Identifica columnas de fecha y demanda por palabras clave
- **Limpieza de datos**: Elimina valores nulos y convierte fechas
- **Indexaci√≥n temporal**: Establece la fecha como √≠ndice
- **Conversi√≥n horaria**: Si los datos son diarios, los convierte a horarios simulados

**Algoritmo de Conversi√≥n Diaria a Horaria**:
```python
if freq_detected is None or freq_detected == 'D':
    for fecha, row in datos.iterrows():
        for hora in range(24):
            # Patr√≥n diario t√≠pico de demanda el√©ctrica
            if 8 <= hora <= 10 or 18 <= hora <= 20:  # Picos
                factor = 1.2 + 0.3 * np.sin(2 * np.pi * hora / 24)
            elif 22 <= hora or hora <= 6:  # Valle nocturno
                factor = 0.6 + 0.2 * np.sin(2 * np.pi * hora / 24)
            else:  # Base
                factor = 0.8 + 0.2 * np.sin(2 * np.pi * hora / 24)
            
            # Agregar variabilidad aleatoria
            factor += np.random.normal(0, 0.1)
            factor = max(0.3, factor)
            
            demanda_horaria = row['Demand'] * factor / 24
```

**Caracter√≠sticas del Patr√≥n Simulado**:
- **Picos**: 8-10 AM y 6-8 PM (factor 1.2-1.5)
- **Valle nocturno**: 10 PM - 6 AM (factor 0.6-0.8)
- **Base**: Resto del d√≠a (factor 0.8-1.0)
- **Variabilidad**: Ruido gaussiano para realismo

### 3. An√°lisis Exploratorio

#### Funci√≥n `exploratory_analysis()`

```python
def exploratory_analysis(datos):
    """
    Realiza an√°lisis exploratorio de la serie temporal
    """
    # Estad√≠sticas b√°sicas
    print(f"üìÖ Per√≠odo: {datos.index.min()} a {datos.index.max()}")
    print(f"‚è±Ô∏è  Duraci√≥n: {(datos.index.max() - datos.index.min()).days} d√≠as")
    print(f"üìà Total observaciones: {len(datos):,}")
    print(f"üïê Frecuencia: {pd.infer_freq(datos.index)}")
    
    # Gr√°fico de la serie temporal completa
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=datos.index, 
        y=datos['Demand'], 
        mode='lines', 
        name='Demanda Energ√©tica',
        line=dict(color='blue', width=1)
    ))
    
    # Gr√°fico de distribuci√≥n
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    ax1.hist(datos['Demand'], bins=50, alpha=0.7, color='skyblue', edgecolor='black')
    ax2.boxplot(datos['Demand'], patch_artist=True, 
                boxprops=dict(facecolor='lightgreen', alpha=0.7))
```

**Funcionalidad**:
- **Estad√≠sticas descriptivas**: Resumen num√©rico de la serie temporal
- **Visualizaci√≥n temporal**: Gr√°fico de l√≠nea de la demanda completa
- **An√°lisis de distribuci√≥n**: Histograma y box plot
- **Detecci√≥n de patrones**: Identificaci√≥n de tendencias y estacionalidad

**M√©tricas Calculadas**:
- Per√≠odo temporal total
- N√∫mero de observaciones
- Frecuencia de los datos
- Estad√≠sticas descriptivas (mean, std, min, max, percentiles)

### 4. Partici√≥n de Datos

#### Funci√≥n `split_data()`

```python
def split_data(datos, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):
    """
    Divide los datos en conjuntos de entrenamiento, validaci√≥n y prueba
    """
    # Verificar que las proporciones sumen 1
    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6
    
    total_len = len(datos)
    train_len = int(total_len * train_ratio)
    val_len = int(total_len * val_ratio)
    
    # Dividir los datos
    datos_train = datos.iloc[:train_len].copy()
    datos_val = datos.iloc[train_len:train_len + val_len].copy()
    datos_test = datos.iloc[train_len + val_len:].copy()
    
    # Obtener fechas de corte
    fin_train = datos_train.index[-1]
    fin_validacion = datos_val.index[-1]
```

**Funcionalidad**:
- **Divisi√≥n temporal**: Respeta el orden cronol√≥gico de los datos
- **Proporciones configurables**: 70% train, 15% val, 15% test por defecto
- **Validaci√≥n de entrada**: Verifica que las proporciones sumen 1
- **Visualizaci√≥n**: Muestra la divisi√≥n con l√≠neas verticales

**Importancia de la Divisi√≥n Temporal**:
- **Evita data leakage**: Los datos futuros no se usan para predecir el pasado
- **Simula condiciones reales**: El modelo se entrena solo con datos hist√≥ricos
- **Validaci√≥n robusta**: Eval√∫a el rendimiento en datos no vistos

### 5. Modelo de Machine Learning

#### Funci√≥n `create_recursive_forecaster()`

```python
def create_recursive_forecaster():
    """
    Crea un forecaster recursivo multi-step con LightGBM
    """
    # Configurar el regresor LightGBM
    regressor = LGBMRegressor(
        n_estimators=100,
        max_depth=6,
        learning_rate=0.1,
        random_state=42,
        verbose=-1
    )
    
    # Crear features de ventana deslizante
    window_features = RollingFeatures(
        stats=["mean", "std"], 
        window_sizes=[24, 24*7]  # 24 horas y 7 d√≠as
    )
    
    # Crear el forecaster recursivo
    forecaster = ForecasterRecursive(
        regressor=regressor,
        lags=24,  # Usar las √∫ltimas 24 horas como predictores
        window_features=window_features
    )
```

**Componentes del Modelo**:

1. **Regresor Base (LightGBM)**:
   - `n_estimators=100`: N√∫mero de √°rboles
   - `max_depth=6`: Profundidad m√°xima de los √°rboles
   - `learning_rate=0.1`: Tasa de aprendizaje
   - `random_state=42`: Semilla para reproducibilidad

2. **Features de Ventana Deslizante**:
   - `window_sizes=[24, 24*7]`: Ventanas de 24 horas y 7 d√≠as
   - `stats=["mean", "std"]`: Media y desviaci√≥n est√°ndar
   - **Prop√≥sito**: Capturar patrones de corto y largo plazo

3. **Lags**:
   - `lags=24`: Usa las √∫ltimas 24 horas como predictores
   - **Prop√≥sito**: Capturar dependencias temporales inmediatas

#### Funci√≥n `train_and_evaluate_model()`

```python
def train_and_evaluate_model(forecaster, datos_train, datos_val, datos_test):
    """
    Entrena el modelo y eval√∫a su rendimiento
    """
    # Entrenar el modelo
    forecaster.fit(y=datos_train['Demand'])
    
    # Realizar predicciones
    predicciones_val = forecaster.predict(steps=len(datos_val))
    predicciones_test = forecaster.predict(steps=len(datos_test))
    
    # Calcular m√©tricas
    def calculate_metrics(y_true, y_pred, dataset_name):
        mae = mean_absolute_error(y_true, y_pred)
        mse = mean_squared_error(y_true, y_pred)
        rmse = np.sqrt(mse)
        r2 = r2_score(y_true, y_pred)
        
        return {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'R2': r2}
```

**Proceso de Entrenamiento**:
1. **Fit**: Entrena el modelo con datos de entrenamiento
2. **Predict**: Genera predicciones para validaci√≥n y prueba
3. **Evaluate**: Calcula m√©tricas de rendimiento

**M√©tricas de Evaluaci√≥n**:
- **MAE (Mean Absolute Error)**: Error absoluto promedio
- **MSE (Mean Squared Error)**: Error cuadr√°tico promedio
- **RMSE (Root Mean Squared Error)**: Ra√≠z del error cuadr√°tico promedio
- **R¬≤ (Coefficient of Determination)**: Coeficiente de determinaci√≥n

### 6. Visualizaciones

#### Funci√≥n `create_scatter_plots()`

```python
def create_scatter_plots(datos_val, predicciones_val, datos_test, predicciones_test):
    """
    Crea gr√°ficos de dispersi√≥n para comparar valores reales vs predichos
    """
    # Crear subplots
    fig, axes = plt.subplots(1, 2, figsize=(15, 6))
    
    # Gr√°fico de dispersi√≥n para validaci√≥n
    axes[0].scatter(datos_val['Demand'], predicciones_val, alpha=0.6, color='blue')
    axes[0].plot([datos_val['Demand'].min(), datos_val['Demand'].max()], 
                 [datos_val['Demand'].min(), datos_val['Demand'].max()], 
                 'r--', lw=2, label='L√≠nea perfecta')
    
    # Gr√°fico interactivo con Plotly
    fig = make_subplots(
        rows=1, cols=2,
        subplot_titles=('Validaci√≥n: Real vs Predicho', 'Prueba: Real vs Predicho')
    )
```

**Tipos de Visualizaciones**:

1. **Gr√°ficos de Dispersi√≥n**:
   - Comparaci√≥n directa entre valores reales y predichos
   - L√≠nea de referencia para predicci√≥n perfecta
   - Identificaci√≥n de sesgos y patrones de error

2. **Series Temporales**:
   - Superposici√≥n de datos reales y predicciones
   - Identificaci√≥n de patrones temporales
   - Evaluaci√≥n visual del rendimiento

3. **Gr√°ficos Interactivos (Plotly)**:
   - Zoom y pan para an√°lisis detallado
   - Tooltips con informaci√≥n espec√≠fica
   - Exportaci√≥n de im√°genes

#### Funci√≥n `create_time_series_plots()`

```python
def create_time_series_plots(datos_train, datos_val, datos_test, predicciones_val, predicciones_test):
    """
    Crea gr√°ficos de series temporales mostrando las predicciones
    """
    fig = go.Figure()
    
    # Datos de entrenamiento
    fig.add_trace(go.Scatter(
        x=datos_train.index,
        y=datos_train['Demand'],
        mode='lines',
        name='Entrenamiento',
        line=dict(color='blue', width=1)
    ))
    
    # Datos reales de validaci√≥n
    fig.add_trace(go.Scatter(
        x=datos_val.index,
        y=datos_val['Demand'],
        mode='lines',
        name='Validaci√≥n (Real)',
        line=dict(color='orange', width=1)
    ))
    
    # Predicciones de validaci√≥n
    fig.add_trace(go.Scatter(
        x=datos_val.index,
        y=predicciones_val,
        mode='lines',
        name='Validaci√≥n (Predicho)',
        line=dict(color='orange', width=2, dash='dash')
    ))
```

**Caracter√≠sticas de las Visualizaciones**:
- **Colores diferenciados**: Cada conjunto de datos tiene un color √∫nico
- **Estilos de l√≠nea**: L√≠neas s√≥lidas para datos reales, punteadas para predicciones
- **Leyendas informativas**: Identificaci√≥n clara de cada elemento
- **Interactividad**: Hover, zoom y pan para an√°lisis detallado

### 7. Predicci√≥n del D√≠a Siguiente

#### Funci√≥n `predict_next_day()`

```python
def predict_next_day(forecaster, datos):
    """
    Predice la demanda energ√©tica para el d√≠a siguiente
    """
    # Obtener la √∫ltima fecha de los datos
    ultima_fecha = datos.index.max()
    
    # Calcular la fecha del d√≠a siguiente
    siguiente_dia = ultima_fecha + pd.Timedelta(days=1)
    
    # Crear fechas para las 24 horas del d√≠a siguiente
    horas_siguiente_dia = pd.date_range(
        start=siguiente_dia.replace(hour=0, minute=0, second=0),
        end=siguiente_dia.replace(hour=23, minute=0, second=0),
        freq='H'
    )
    
    # Realizar la predicci√≥n para las 24 horas del d√≠a siguiente
    prediccion_siguiente = forecaster.predict(steps=24)
    
    # Calcular estad√≠sticas de la predicci√≥n
    demanda_total_dia = prediccion_siguiente.sum()
    demanda_promedio = prediccion_siguiente.mean()
    demanda_maxima = prediccion_siguiente.max()
    demanda_minima = prediccion_siguiente.min()
    hora_pico = horas_siguiente_dia[prediccion_siguiente.argmax()]
    hora_valle = horas_siguiente_dia[prediccion_siguiente.argmin()]
```

**Funcionalidad**:
- **C√°lculo de fechas**: Determina autom√°ticamente el d√≠a siguiente
- **Generaci√≥n de timestamps**: Crea 24 horas consecutivas
- **Predicci√≥n multi-step**: Genera 24 predicciones secuenciales
- **An√°lisis estad√≠stico**: Calcula m√©tricas de resumen

**Estad√≠sticas Calculadas**:
- **Demanda total del d√≠a**: Suma de las 24 horas
- **Demanda promedio**: Media de las predicciones
- **Demanda m√°xima/m√≠nima**: Picos y valles
- **Horas de pico/valle**: Timestamps de extremos

#### Funci√≥n `visualize_next_day_prediction()`

```python
def visualize_next_day_prediction(datos, horas_siguiente_dia, prediccion_siguiente):
    """
    Visualiza la predicci√≥n del d√≠a siguiente junto con datos hist√≥ricos
    """
    # Agregar datos hist√≥ricos de los √∫ltimos 7 d√≠as para contexto
    datos_historicos = datos.tail(7 * 24)  # √öltimos 7 d√≠as
    
    # Agregar predicci√≥n del d√≠a siguiente
    fig.add_trace(go.Scatter(
        x=horas_siguiente_dia, 
        y=prediccion_siguiente, 
        mode='lines+markers', 
        name=f'Predicci√≥n {horas_siguiente_dia[0].date()}',
        line=dict(color='red', width=3),
        marker=dict(size=6, color='red')
    ))
    
    # Crear gr√°fico de barras para la predicci√≥n del d√≠a siguiente
    fig_barras = go.Figure()
    fig_barras.add_trace(go.Bar(
        x=[h.strftime('%H:%M') for h in horas_siguiente_dia],
        y=prediccion_siguiente,
        name='Demanda Predicha',
        marker_color='lightcoral'
    ))
```

**Tipos de Visualizaciones**:
1. **Serie temporal con contexto**: √öltimos 7 d√≠as + predicci√≥n
2. **Gr√°fico de barras horario**: Predicci√≥n por hora del d√≠a
3. **L√≠neas de separaci√≥n**: Distinci√≥n entre hist√≥rico y predicci√≥n

---

## Funciones Principales

### Resumen de Funciones

| Funci√≥n | Prop√≥sito | Entrada | Salida |
|---------|-----------|---------|--------|
| `load_energy_data()` | Cargar archivos Excel | Carpeta con archivos | DataFrame combinado |
| `preprocess_data()` | Procesar y limpiar datos | DataFrame raw | Serie temporal limpia |
| `exploratory_analysis()` | An√°lisis exploratorio | Serie temporal | Estad√≠sticas y gr√°ficos |
| `split_data()` | Dividir datos | Serie temporal | Train/Val/Test sets |
| `create_recursive_forecaster()` | Crear modelo | Par√°metros | Forecaster configurado |
| `train_and_evaluate_model()` | Entrenar y evaluar | Modelo + datos | M√©tricas de rendimiento |
| `create_scatter_plots()` | Gr√°ficos de dispersi√≥n | Predicciones | Visualizaciones |
| `create_time_series_plots()` | Series temporales | Datos + predicciones | Gr√°ficos temporales |
| `predict_next_day()` | Predicci√≥n futura | Modelo entrenado | Predicci√≥n 24h |
| `visualize_next_day_prediction()` | Visualizar predicci√≥n | Predicci√≥n | Gr√°ficos finales |

---

## Flujo de Datos

### Diagrama de Flujo Detallado

```mermaid
flowchart TD
    A[Archivos Excel 2000-2025] --> B[load_energy_data]
    B --> C[preprocess_data]
    C --> D[exploratory_analysis]
    D --> E[split_data]
    E --> F[create_recursive_forecaster]
    F --> G[train_and_evaluate_model]
    G --> H[create_scatter_plots]
    G --> I[create_time_series_plots]
    G --> J[predict_next_day]
    J --> K[visualize_next_day_prediction]
    K --> L[Exportaci√≥n CSV]
    
    style A fill:#e1f5fe
    style L fill:#c8e6c9
    style F fill:#fff3e0
    style G fill:#fce4ec
```

### Transformaciones de Datos

1. **Raw Data ‚Üí Clean Data**:
   - Detecci√≥n autom√°tica de columnas
   - Conversi√≥n de fechas
   - Eliminaci√≥n de valores nulos
   - Conversi√≥n diaria a horaria (si es necesario)

2. **Clean Data ‚Üí Time Series**:
   - Indexaci√≥n temporal
   - Ordenamiento cronol√≥gico
   - Establecimiento de frecuencia

3. **Time Series ‚Üí Train/Val/Test**:
   - Divisi√≥n temporal respetando orden
   - Proporciones configurables
   - Validaci√≥n de integridad

4. **Train Data ‚Üí Model Features**:
   - Creaci√≥n de lags (24 horas)
   - Features de ventana deslizante
   - Estad√≠sticas agregadas

---

## Modelo de Machine Learning

### Arquitectura del Modelo

```python
ForecasterRecursive(
    regressor=LGBMRegressor(
        n_estimators=100,      # N√∫mero de √°rboles
        max_depth=6,           # Profundidad m√°xima
        learning_rate=0.1,     # Tasa de aprendizaje
        random_state=42        # Reproducibilidad
    ),
    lags=24,                   # √öltimas 24 horas
    window_features=RollingFeatures(
        stats=["mean", "std"], # Estad√≠sticas
        window_sizes=[24, 168] # 24h y 7 d√≠as
    )
)
```

### Proceso de Forecasting Recursivo

1. **Entrenamiento**:
   - El modelo aprende a predecir t+1 usando datos hist√≥ricos
   - Se entrenan features de ventana y lags
   - LightGBM optimiza los par√°metros internamente

2. **Predicci√≥n Multi-Step**:
   ```
   t+1 = modelo(√∫ltimas_24h, features_ventana)
   t+2 = modelo([√∫ltimas_23h, t+1], features_ventana)
   t+3 = modelo([√∫ltimas_22h, t+1, t+2], features_ventana)
   ...
   t+24 = modelo([t+1, t+2, ..., t+23], features_ventana)
   ```

3. **Ventajas del M√©todo**:
   - **Captura dependencias**: Aprende patrones de largo plazo
   - **Eficiencia**: Un solo modelo para m√∫ltiples pasos
   - **Realismo**: Simula condiciones de predicci√≥n reales

### Features Engineering

#### Lags (Retrasos)
- **Prop√≥sito**: Capturar dependencias temporales inmediatas
- **Valor**: 24 horas (√∫ltimo d√≠a completo)
- **Beneficio**: El modelo ve patrones diarios completos

#### Rolling Features (Features de Ventana)
- **Ventana 24h**: Media y desviaci√≥n est√°ndar del √∫ltimo d√≠a
- **Ventana 7 d√≠as**: Media y desviaci√≥n est√°ndar de la √∫ltima semana
- **Prop√≥sito**: Capturar tendencias y variabilidad

#### Estad√≠sticas Calculadas
- **Mean**: Tendencia central de la ventana
- **Std**: Variabilidad de la demanda
- **Beneficio**: Informaci√≥n sobre estabilidad y patrones

---

## Visualizaciones

### Tipos de Gr√°ficos Implementados

#### 1. An√°lisis Exploratorio
- **Serie temporal completa**: Toda la demanda hist√≥rica
- **Histograma**: Distribuci√≥n de valores de demanda
- **Box plot**: Identificaci√≥n de outliers y cuartiles

#### 2. Evaluaci√≥n del Modelo
- **Gr√°ficos de dispersi√≥n**: Real vs Predicho
- **Series temporales**: Superposici√≥n de predicciones
- **Zoom temporal**: An√°lisis de per√≠odos espec√≠ficos

#### 3. Predicci√≥n Final
- **Contexto hist√≥rico**: √öltimos 7 d√≠as + predicci√≥n
- **Gr√°fico de barras**: Predicci√≥n por hora
- **L√≠neas de separaci√≥n**: Distinci√≥n temporal

### Tecnolog√≠as de Visualizaci√≥n

#### Matplotlib/Seaborn
- **Uso**: Gr√°ficos est√°ticos de an√°lisis
- **Ventajas**: Control total, personalizaci√≥n
- **Casos**: Histogramas, box plots, scatter plots

#### Plotly
- **Uso**: Gr√°ficos interactivos principales
- **Ventajas**: Interactividad, zoom, hover
- **Casos**: Series temporales, predicciones

### Configuraci√≥n de Estilos

```python
# Configuraci√≥n de visualizaci√≥n
plt.style.use('seaborn-v0_8-darkgrid')
plt.rcParams.update({'font.size': 10})
sns.set_palette("husl")
```

---

## M√©tricas de Evaluaci√≥n

### M√©tricas Implementadas

#### 1. Mean Absolute Error (MAE)
```python
mae = mean_absolute_error(y_true, y_pred)
```
- **F√≥rmula**: MAE = (1/n) √ó Œ£|y_true - y_pred|
- **Interpretaci√≥n**: Error promedio en las mismas unidades
- **Uso**: Comparaci√≥n directa con la escala de demanda

#### 2. Mean Squared Error (MSE)
```python
mse = mean_squared_error(y_true, y_pred)
```
- **F√≥rmula**: MSE = (1/n) √ó Œ£(y_true - y_pred)¬≤
- **Interpretaci√≥n**: Penaliza errores grandes
- **Uso**: Optimizaci√≥n del modelo

#### 3. Root Mean Squared Error (RMSE)
```python
rmse = np.sqrt(mse)
```
- **F√≥rmula**: RMSE = ‚àöMSE
- **Interpretaci√≥n**: Error en las mismas unidades que MAE
- **Uso**: Interpretaci√≥n m√°s intuitiva que MSE

#### 4. Coefficient of Determination (R¬≤)
```python
r2 = r2_score(y_true, y_pred)
```
- **F√≥rmula**: R¬≤ = 1 - (SS_res / SS_tot)
- **Interpretaci√≥n**: Proporci√≥n de varianza explicada
- **Rango**: 0 a 1 (mejor = m√°s cercano a 1)

### Interpretaci√≥n de M√©tricas

| M√©trica | Excelente | Bueno | Aceptable | Malo |
|---------|-----------|-------|-----------|------|
| MAE | < 5% | 5-10% | 10-15% | > 15% |
| RMSE | < 7% | 7-12% | 12-18% | > 18% |
| R¬≤ | > 0.95 | 0.90-0.95 | 0.80-0.90 | < 0.80 |

### Validaci√≥n Cruzada Temporal

```python
# El modelo se eval√∫a en:
# 1. Conjunto de validaci√≥n (15% de datos)
# 2. Conjunto de prueba (15% de datos)
# 3. Ambos respetan el orden temporal
```

---

## Casos de Uso

### 1. Predicci√≥n Operativa
- **Objetivo**: Planificar generaci√≥n el√©ctrica
- **Horizonte**: 24 horas
- **Frecuencia**: Diaria
- **Precisi√≥n requerida**: Alta (MAE < 5%)

### 2. An√°lisis de Tendencia
- **Objetivo**: Identificar patrones de demanda
- **Horizonte**: Largo plazo
- **Frecuencia**: Semanal/mensual
- **Precisi√≥n requerida**: Media (MAE 5-10%)

### 3. Investigaci√≥n Acad√©mica
- **Objetivo**: Estudiar comportamiento de demanda
- **Horizonte**: Variable
- **Frecuencia**: Seg√∫n necesidad
- **Precisi√≥n requerida**: Variable

### 4. Optimizaci√≥n de Red
- **Objetivo**: Minimizar costos operativos
- **Horizonte**: 24-48 horas
- **Frecuencia**: Continua
- **Precisi√≥n requerida**: Alta (MAE < 5%)

---

## Troubleshooting

### Problemas Comunes y Soluciones

#### 1. Error de Memoria
**S√≠ntoma**: `MemoryError` durante el entrenamiento
**Causa**: Dataset muy grande para la memoria disponible
**Soluci√≥n**:
```python
# Reducir el tama√±o del dataset
datos_sample = datos.sample(n=100000, random_state=42)

# O usar un subconjunto temporal
datos_recent = datos.tail(365*24*2)  # √öltimos 2 a√±os
```

#### 2. Error de Convergencia
**S√≠ntoma**: Modelo no converge o da predicciones extra√±as
**Causa**: Par√°metros de LightGBM inadecuados
**Soluci√≥n**:
```python
# Ajustar par√°metros del modelo
regressor = LGBMRegressor(
    n_estimators=50,      # Reducir √°rboles
    max_depth=4,          # Reducir profundidad
    learning_rate=0.05,   # Reducir tasa de aprendizaje
    min_child_samples=20  # Aumentar muestras m√≠nimas
)
```

#### 3. Predicciones Constantes
**S√≠ntoma**: Todas las predicciones son iguales
**Causa**: Modelo no est√° aprendiendo patrones
**Soluci√≥n**:
```python
# Verificar que hay variabilidad en los datos
print(f"Variabilidad en demanda: {datos['Demand'].std()}")

# Aumentar lags para capturar m√°s patrones
forecaster = ForecasterRecursive(
    regressor=regressor,
    lags=48,  # Usar 48 horas en lugar de 24
    window_features=window_features
)
```

#### 4. Error de Formato de Datos
**S√≠ntoma**: `KeyError` al acceder a columnas
**Causa**: Nombres de columnas no detectados autom√°ticamente
**Soluci√≥n**:
```python
# Verificar nombres de columnas
print("Columnas disponibles:", datos.columns.tolist())

# Especificar columnas manualmente
datos = datos_raw[['Fecha', 'Demanda']].copy()
datos.columns = ['Time', 'Demand']
```

#### 5. Error de Fechas
**S√≠ntoma**: `TypeError` al procesar fechas
**Causa**: Formato de fecha no reconocido
**Soluci√≥n**:
```python
# Especificar formato de fecha
datos['Time'] = pd.to_datetime(datos['Time'], format='%Y-%m-%d %H:%M:%S')

# O usar infer_datetime_format
datos['Time'] = pd.to_datetime(datos['Time'], infer_datetime_format=True)
```

### Optimizaci√≥n de Rendimiento

#### 1. Acelerar Entrenamiento
```python
# Usar menos estimadores para pruebas r√°pidas
regressor = LGBMRegressor(
    n_estimators=50,  # En lugar de 100
    verbose=-1        # Silenciar output
)

# Usar subconjunto de datos para desarrollo
datos_dev = datos.sample(n=50000, random_state=42)
```

#### 2. Mejorar Precisi√≥n
```python
# Aumentar estimadores para mejor precisi√≥n
regressor = LGBMRegressor(
    n_estimators=200,     # M√°s √°rboles
    max_depth=8,          # M√°s profundidad
    learning_rate=0.05,   # Tasa de aprendizaje m√°s baja
    num_leaves=31         # M√°s hojas por √°rbol
)
```

#### 3. Reducir Overfitting
```python
# Agregar regularizaci√≥n
regressor = LGBMRegressor(
    reg_alpha=0.1,        # Regularizaci√≥n L1
    reg_lambda=0.1,       # Regularizaci√≥n L2
    min_child_samples=20, # M√≠nimo de muestras por hoja
    subsample=0.8         # Submuestreo de filas
)
```

---

## Conclusi√≥n

Este notebook implementa un sistema completo de forecasting recursivo multi-step para la predicci√≥n de demanda energ√©tica. La arquitectura modular permite f√°cil mantenimiento y extensi√≥n, mientras que las visualizaciones interactivas facilitan la interpretaci√≥n de resultados.

### Puntos Clave

1. **Metodolog√≠a Robusta**: Forecasting recursivo con validaci√≥n temporal
2. **C√≥digo Modular**: Funciones bien documentadas y reutilizables
3. **Visualizaciones Completas**: An√°lisis exploratorio y evaluaci√≥n del modelo
4. **Predicci√≥n Pr√°ctica**: Generaci√≥n de pron√≥sticos para el d√≠a siguiente
5. **Exportaci√≥n de Resultados**: Archivos CSV para uso posterior

### Extensiones Posibles

1. **Variables Ex√≥genas**: Incorporar temperatura, festivos, eventos especiales
2. **M√∫ltiples Modelos**: Comparar diferentes algoritmos (XGBoost, Random Forest)
3. **Intervalos de Confianza**: Agregar incertidumbre a las predicciones
4. **Optimizaci√≥n de Hiperpar√°metros**: B√∫squeda autom√°tica de mejores par√°metros
5. **Predicci√≥n Multi-Horizonte**: Extender a 48 o 72 horas

El c√≥digo est√° dise√±ado para ser educativo, pr√°ctico y extensible, proporcionando una base s√≥lida para proyectos de forecasting de demanda energ√©tica.
